# Kafka Test Application

–¢–µ—Å—Ç–æ–≤–æ–µ Go –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ Producer –∏ Consumer —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ Apache Kafka –ø–µ—Ä–µ–¥ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Å Telegram –±–æ—Ç–æ–º.

## –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è:
- üß™ **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è** —Ä–∞–±–æ—Ç—ã Kafka –ø–µ—Ä–µ–¥ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Å –±–æ—Ç–æ–º
- üìö **–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏** –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ Producer/Consumer
- üîç **–û—Ç–ª–∞–¥–∫–∏** –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Kafka
- üìñ **–û–±—É—á–µ–Ω–∏—è** —Ä–∞–±–æ—Ç–µ —Å Kafka –≤ Go

## –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç –¥–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ:

1. **Producer** - –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã:
   ```
   key: "key-1"
   value: "message-1 at 2025-11-29T12:00:00Z"
   ```

2. **Consumer** - —á–∏—Ç–∞–µ—Ç –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Ç–æ–ø–∏–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:
   ```
   Message received: key=key-1, value=message-1 at 2025-11-29T12:00:00Z
   ```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
kafka-test/
‚îú‚îÄ‚îÄ main.go              # –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞, –∑–∞–ø—É—Å–∫ Producer/Consumer
‚îú‚îÄ‚îÄ config.yaml          # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (brokers, topics, env)
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.go        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ
‚îî‚îÄ‚îÄ kafka/
    ‚îú‚îÄ‚îÄ producer.go      # Kafka Producer
    ‚îî‚îÄ‚îÄ consumer.go      # Kafka Consumer
```

## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Kafka –∑–∞–ø—É—â–µ–Ω

```bash
cd ../kafka
docker-compose up -d
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
go mod download
```

### 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

```bash
go run main.go
```

### 4. –ù–∞–±–ª—é–¥–∞–π—Ç–µ –∑–∞ —Ä–∞–±–æ—Ç–æ–π

–í—ã —É–≤–∏–¥–∏—Ç–µ –ª–æ–≥–∏:

```
2025/11/29 12:00:00 Starting Kafka test application (env: local)
2025/11/29 12:00:00 Brokers: [localhost:9092], Topic: test-topic
2025/11/29 12:00:00 Starting to read messages...
2025/11/29 12:00:00 Application is running. Press Ctrl+C to stop.
2025/11/29 12:00:03 Message sent: key=key-1, value=message-1 at 2025-11-29T12:00:03Z
2025/11/29 12:00:03 Message received: key=key-1, value=message-1 at 2025-11-29T12:00:03Z, partition=0, offset=0
2025/11/29 12:00:06 Message sent: key=key-2, value=message-2 at 2025-11-29T12:00:06Z
2025/11/29 12:00:06 Message received: key=key-2, value=message-2 at 2025-11-29T12:00:06Z, partition=0, offset=1
```

### 5. –û—Å—Ç–∞–Ω–æ–≤–∫–∞

–ù–∞–∂–º–∏—Ç–µ `Ctrl+C` –¥–ª—è graceful shutdown:

```
2025/11/29 12:00:15 Shutting down...
2025/11/29 12:00:15 Consumer context cancelled
2025/11/29 12:00:16 Application stopped.
```

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### config.yaml

```yaml
kafka:
  local:
    brokers:
      - "localhost:9092"
    topic: "test-topic"
    group_id: "test-consumer-group"
  
  production:
    brokers:
      - "kafka-prod:9092"
    topic: "prod-topic"
    group_id: "prod-consumer-group"

env: "local"  # local –∏–ª–∏ production
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä |
|----------|----------|--------|
| `brokers` | –ê–¥—Ä–µ—Å–∞ Kafka –±—Ä–æ–∫–µ—Ä–æ–≤ | `["localhost:9092"]` |
| `topic` | –ò–º—è —Ç–æ–ø–∏–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è | `test-topic` |
| `group_id` | ID consumer group | `test-consumer-group` |
| `env` | –û–∫—Ä—É–∂–µ–Ω–∏–µ (local/production) | `local` |

### –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–ò–∑–º–µ–Ω–∏—Ç–µ `env: "production"` –≤ `config.yaml` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

## –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### Producer (kafka/producer.go)

```go
type Producer struct {
    writer *kafka.Writer
}

func NewProducer(brokers []string, topic string) *Producer {
    writer := &kafka.Writer{
        Addr:     kafka.TCP(brokers...),
        Topic:    topic,
        Balancer: &kafka.LeastBytes{},  // –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä—É
    }
    return &Producer{writer: writer}
}

func (p *Producer) SendMessage(ctx context.Context, key, value string) error {
    msg := kafka.Message{
        Key:   []byte(key),
        Value: []byte(value),
    }
    return p.writer.WriteMessages(ctx, msg)
}
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫ `LeastBytes` - –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ –ø–∞—Ä—Ç–∏—Ü–∏—é —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –æ–±—ä–µ–º–æ–º –¥–∞–Ω–Ω—ã—Ö
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è graceful shutdown
- –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

### Consumer (kafka/consumer.go)

```go
type Consumer struct {
    reader *kafka.Reader
}

func NewConsumer(brokers []string, topic, groupID string) *Consumer {
    reader := kafka.NewReader(kafka.ReaderConfig{
        Brokers:  brokers,
        Topic:    topic,
        GroupID:  groupID,
        MinBytes: 10e3,  // 10KB
        MaxBytes: 10e6,  // 10MB
    })
    return &Consumer{reader: reader}
}

func (c *Consumer) ReadMessages(ctx context.Context) error {
    for {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            msg, err := c.reader.ReadMessage(ctx)
            if err != nil {
                return fmt.Errorf("failed to read message: %w", err)
            }
            log.Printf("Message received: key=%s, value=%s, partition=%d, offset=%d\n",
                string(msg.Key), string(msg.Value), msg.Partition, msg.Offset)
        }
    }
}
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- Consumer group –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞–º–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π commit –æ—Ñ—Ñ—Å–µ—Ç–æ–≤
- MinBytes/MaxBytes –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

### –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª (main.go)

```go
func main() {
    cfg := config.MustLoad("config.yaml")
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    producer := kafka.NewProducer(kafkaCfg.Brokers, kafkaCfg.Topic)
    consumer := kafka.NewConsumer(kafkaCfg.Brokers, kafkaCfg.Topic, kafkaCfg.GroupID)

    // Consumer –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≥–æ—Ä—É—Ç–∏–Ω–µ
    go consumer.ReadMessages(ctx)

    // Producer —Å ticker
    go func() {
        ticker := time.NewTicker(3 * time.Second)
        for {
            select {
            case <-ctx.Done():
                return
            case <-ticker.C:
                producer.SendMessage(ctx, key, value)
            }
        }
    }()

    // Graceful shutdown
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)
    <-sigChan
    cancel()
}
```

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```go
require (
    github.com/ilyakaznacheev/cleanenv v1.5.0  // –ü–∞—Ä—Å–∏–Ω–≥ YAML
    github.com/segmentio/kafka-go v0.4.49      // Kafka –∫–ª–∏–µ–Ω—Ç
)
```

**–ü–æ—á–µ–º—É segmentio/kafka-go?**
- ‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π API
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç CGO (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç confluent-kafka-go)
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
- ‚úÖ –•–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã

### –ò–∑–º–µ–Ω–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª –æ—Ç–ø—Ä–∞–≤–∫–∏

–í `main.go`:

```go
ticker := time.NewTicker(5 * time.Second)  // –ë—ã–ª–æ 3 —Å–µ–∫—É–Ω–¥—ã
```

### –ò–∑–º–µ–Ω–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏–π

–í `main.go`:

```go
// –ë—ã–ª–æ
value := fmt.Sprintf("message-%d at %s", counter, time.Now().Format(time.RFC3339))

// –°—Ç–∞–ª–æ (JSON)
type Message struct {
    ID        int       `json:"id"`
    Content   string    `json:"content"`
    Timestamp time.Time `json:"timestamp"`
}
msg := Message{ID: counter, Content: "Hello", Timestamp: time.Now()}
value, _ := json.Marshal(msg)
```

### –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π

–í `kafka/consumer.go`:

```go
func (c *Consumer) ReadMessages(ctx context.Context) error {
    for {
        msg, err := c.reader.ReadMessage(ctx)
        if err != nil {
            return err
        }

        // –î–æ–±–∞–≤–∏—Ç—å —Å–≤–æ—é –ª–æ–≥–∏–∫—É
        if err := processMessage(msg); err != nil {
            log.Printf("Processing error: %v\n", err)
        }
    }
}

func processMessage(msg kafka.Message) error {
    // –í–∞—à–∞ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
    var data MyDataType
    json.Unmarshal(msg.Value, &data)
    // ...
    return nil
}
```

### –î–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–ø–∏–∫–æ–≤

```go
topics := []string{"topic-1", "topic-2", "topic-3"}

for _, topic := range topics {
    producer := kafka.NewProducer(brokers, topic)
    go producer.SendMessage(ctx, "key", "value")
}
```

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Telegram –±–æ—Ç–æ–º

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å Kafka –≤ –±–æ—Ç–∞:

### 1. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å Producer/Consumer

```bash
cp kafka-test/kafka/* tgbot/internal/kafka/
```

### 2. –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–æ–±—ã—Ç–∏—è –∏–∑ –±–æ—Ç–∞

```go
// –í RegService –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
func (r *RegService) Reg(tgID int64, username string) error {
    // ... —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ...

    // –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ Kafka
    event := map[string]interface{}{
        "event_type": "user.registered",
        "user_id":    id.String(),
        "tg_id":      tgID,
        "username":   username,
        "timestamp":  time.Now().Unix(),
    }
    eventJSON, _ := json.Marshal(event)
    r.kafkaProducer.SendMessage(ctx, id.String(), string(eventJSON))

    return nil
}
```

### 3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã —á–µ—Ä–µ–∑ Kafka

```go
// –°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥ –∏–∑ Kafka
type CommandProcessor struct {
    consumer *kafka.Consumer
    bot      *tele.Bot
}

func (p *CommandProcessor) ProcessCommands(ctx context.Context) {
    for {
        msg, _ := p.consumer.ReadMessage(ctx)
        
        var cmd Command
        json.Unmarshal(msg.Value, &cmd)
        
        // –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É —á–µ—Ä–µ–∑ –±–æ—Ç–∞
        p.bot.Send(cmd.ChatID, cmd.Response)
    }
}
```

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```go
// –î–æ–±–∞–≤–∏—Ç—å –≤ main.go
ticker := time.NewTicker(100 * time.Millisecond)  // 10 —Å–æ–æ–±—â–µ–Ω–∏–π/—Å–µ–∫

var sentCount, receivedCount atomic.Int64

go func() {
    for range ticker.C {
        producer.SendMessage(ctx, key, value)
        sentCount.Add(1)
    }
}()

go func() {
    for {
        consumer.ReadMessage(ctx)
        receivedCount.Add(1)
    }
}()

// –ö–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥ –≤—ã–≤–æ–¥–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
go func() {
    for range time.Tick(10 * time.Second) {
        log.Printf("Sent: %d, Received: %d\n", sentCount.Load(), receivedCount.Load())
    }
}()
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
go run main.go

# –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Kafka
docker-compose -f ../kafka/docker-compose.yml down

# –ü–æ–¥–æ–∂–¥–∞—Ç—å 10 —Å–µ–∫—É–Ω–¥

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–Ω–æ–≤–∞
docker-compose -f ../kafka/docker-compose.yml up -d

# –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è
```

## Troubleshooting

### "Connection refused" –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∑–∞–ø—É—â–µ–Ω –ª–∏ Kafka
docker ps | grep kafka

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä—Ç
telnet localhost 9092

# –ï—Å–ª–∏ –Ω–µ –∑–∞–ø—É—â–µ–Ω - –∑–∞–ø—É—Å—Ç–∏—Ç—å
cd ../kafka && docker-compose up -d
```

### –°–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–æ–ø–∏–∫
docker exec -it kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# –°–æ–∑–¥–∞—Ç—å —Ç–æ–ø–∏–∫ –≤—Ä—É—á–Ω—É—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
docker exec -it kafka kafka-topics.sh --create \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --partitions 1 \
  --replication-factor 1
```

### Consumer –Ω–µ —á–∏—Ç–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è

–ò–∑–º–µ–Ω–∏—Ç–µ –≤ `kafka/consumer.go`:

```go
reader := kafka.NewReader(kafka.ReaderConfig{
    Brokers:  brokers,
    Topic:    topic,
    GroupID:  groupID,
    MinBytes: 10e3,
    MaxBytes: 10e6,
    StartOffset: kafka.FirstOffset,  // –î–æ–±–∞–≤–∏—Ç—å —ç—Ç—É —Å—Ç—Ä–æ–∫—É
})
```

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

1. ‚úÖ –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ Producer –∏ Consumer —Ä–∞–±–æ—Ç–∞—é—Ç
2. ‚úÖ –ü–æ–Ω—è—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—Ç–ø—Ä–∞–≤–∫–∏/–ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
3. üîÑ –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ –≤ –ø—Ä–æ–µ–∫—Ç —Å –±–æ—Ç–æ–º
4. üîÑ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å Producer –¥–ª—è —Å–æ–±—ã—Ç–∏–π –±–æ—Ç–∞
5. üîÑ –î–æ–±–∞–≤–∏—Ç—å Consumer –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥
6. üìä –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç–∏–Ω–≥

## –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å verbose –ª–æ–≥–∞–º–∏
go run main.go 2>&1 | tee kafka-test.log

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ç–æ–ø–∏–∫–µ
docker exec -it kafka kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic test-topic

# –ü—Ä–æ—á–∏—Ç–∞—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Ç–æ–ø–∏–∫–∞
docker exec -it kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --from-beginning
```